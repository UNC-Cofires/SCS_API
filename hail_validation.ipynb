{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Hail Validation Analysis: Brier Score Evaluation\n",
        "\n",
        "This notebook provides comprehensive validation of hail forecasts using Brier scores.\n",
        "\n",
        "## Analysis Components:\n",
        "1. **Data Loading** - PPH, Convective Outlooks, and NCEI Storm Reports\n",
        "2. **Grid Processing** - Convert all data to consistent NAM212 grid\n",
        "3. **Brier Score Calculation** - Evaluate forecast skill against observations\n",
        "4. **Brier Skill Score** - Compare against climatological baseline\n",
        "5. **Comprehensive Validation** - Multiple thresholds and time periods\n",
        "\n",
        "## Key Features:\n",
        "- ✅ Handles projection changes in convective outlook data (pre-2020 vs post-2020)\n",
        "- ✅ Uses actual NCEI storm reports as ground truth\n",
        "- ✅ Computes climatological baseline for skill scores\n",
        "- ✅ Efficient caching system for large data processing\n",
        "- ✅ Proper Brier score implementation following meteorological standards\n",
        "\n",
        "## Validation Period: 2010-2024\n",
        "## Thresholds: 5%, 15%, 30%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from shapely.geometry import Point, Polygon, box\n",
        "from shapely.ops import unary_union, transform\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from scipy.interpolate import griddata\n",
        "from scipy.ndimage import binary_dilation\n",
        "import pyproj\n",
        "from functools import partial\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['legend.fontsize'] = 12\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "print(\"📊 Matplotlib settings configured for validation plots\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration and Paths\n",
        "BASE_PATH = Path(\"/Users/jimnguyen/IRMII/SCS_API\")\n",
        "OUTLOOK_PATH = BASE_PATH / \"convective_outlooks_only1200z\"\n",
        "PPH_HAIL_PATH = BASE_PATH / \"PPH\" / \"NCEI_PPH\" / \"hail\"\n",
        "REPORTS_HAIL_PATH = BASE_PATH / \"NCEI_storm_reports\" / \"hail_filtered\"\n",
        "NAM212_PATH = BASE_PATH / \"PPH\" / \"nam212.nc\"\n",
        "CACHE_PATH = BASE_PATH / \"cache\"\n",
        "\n",
        "# Output directory structure\n",
        "OUTPUT_PATH = BASE_PATH / \"validation_outputs\"\n",
        "FIGURES_PATH = OUTPUT_PATH / \"figures\"\n",
        "BRIER_SCORES_PATH = FIGURES_PATH / \"brier_scores\"\n",
        "VALIDATION_PATH = FIGURES_PATH / \"validation\"\n",
        "\n",
        "START_YEAR = 2010\n",
        "END_YEAR = 2024\n",
        "HAIL_THRESHOLDS = [5, 15, 30]  # Probability thresholds to validate\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(CACHE_PATH, exist_ok=True)\n",
        "os.makedirs(BRIER_SCORES_PATH, exist_ok=True)\n",
        "os.makedirs(VALIDATION_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Configuration set for {START_YEAR}-{END_YEAR}\")\n",
        "print(f\"📁 Output directories created:\")\n",
        "print(f\"   🎯 Brier Scores: {BRIER_SCORES_PATH}\")\n",
        "print(f\"   ✅ Validation: {VALIDATION_PATH}\")\n",
        "print(f\"   💾 Cache: {CACHE_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load NAM212 Grid\n",
        "nam212_ds = xr.open_dataset(NAM212_PATH)\n",
        "grid_lats = nam212_ds['gridlat_212'].values\n",
        "grid_lons = nam212_ds['gridlon_212'].values\n",
        "grid_shape = grid_lats.shape\n",
        "CELL_AREA_KM2 = 40.6 * 40.6\n",
        "\n",
        "print(f\"🗺️ NAM212 Grid: {grid_shape[0]} x {grid_shape[1]} = {grid_shape[0] * grid_shape[1]:,} cells\")\n",
        "print(f\"📏 Cell area: {CELL_AREA_KM2:,.1f} km² per cell\")\n",
        "print(f\"🌍 Grid bounds: Lat [{np.min(grid_lats):.1f}, {np.max(grid_lats):.1f}], Lon [{np.min(grid_lons):.1f}, {np.max(grid_lons):.1f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility Functions for Data Loading\n",
        "def shapefile_to_nam212_grid(shapefile_path, threshold_value, grid_shape, grid_lons, grid_lats):\n",
        "    \"\"\"Convert shapefile polygons to NAM212 grid format with projection handling.\"\"\"\n",
        "    try:\n",
        "        gdf = gpd.read_file(shapefile_path)\n",
        "        grid = np.zeros(grid_shape)\n",
        "        \n",
        "        if len(gdf) == 0:\n",
        "            return grid\n",
        "        \n",
        "        # Filter by threshold using DN column\n",
        "        if 'DN' in gdf.columns:\n",
        "            threshold_gdf = gdf[gdf['DN'] == threshold_value].copy()\n",
        "        else:\n",
        "            threshold_rows = []\n",
        "            for idx, row in gdf.iterrows():\n",
        "                if str(threshold_value) in str(row.to_dict()):\n",
        "                    threshold_rows.append(row)\n",
        "            if threshold_rows:\n",
        "                threshold_gdf = gpd.GeoDataFrame(threshold_rows, crs=gdf.crs)\n",
        "            else:\n",
        "                return grid\n",
        "        \n",
        "        if len(threshold_gdf) == 0:\n",
        "            return grid\n",
        "        \n",
        "        # Check projection and reproject if needed\n",
        "        sample_geom = threshold_gdf.iloc[0].geometry\n",
        "        if sample_geom is not None:\n",
        "            if hasattr(sample_geom, 'exterior'):\n",
        "                x, y = list(sample_geom.exterior.coords)[0]\n",
        "            else:\n",
        "                x, y = list(sample_geom.geoms[0].exterior.coords)[0]\n",
        "            \n",
        "            # If coordinates > 180, it's projected (Lambert Conformal Conic)\n",
        "            if abs(x) > 180 or abs(y) > 90:\n",
        "                threshold_gdf = threshold_gdf.to_crs('EPSG:4326')\n",
        "        \n",
        "        # Merge polygons and check grid points\n",
        "        all_geoms = [row.geometry for idx, row in threshold_gdf.iterrows() \n",
        "                    if row.geometry is not None and row.geometry.is_valid]\n",
        "        \n",
        "        if not all_geoms:\n",
        "            return grid\n",
        "            \n",
        "        merged_geom = unary_union(all_geoms)\n",
        "        if merged_geom.is_empty:\n",
        "            return grid\n",
        "            \n",
        "        minx, miny, maxx, maxy = merged_geom.bounds\n",
        "        \n",
        "        for i in range(grid_shape[0]):\n",
        "            for j in range(grid_shape[1]):\n",
        "                lon, lat = grid_lons[i, j], grid_lats[i, j]\n",
        "                if minx <= lon <= maxx and miny <= lat <= maxy:\n",
        "                    if merged_geom.contains(Point(lon, lat)):\n",
        "                        grid[i, j] = 1.0\n",
        "        \n",
        "        return grid\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️ Error processing {shapefile_path}: {e}\")\n",
        "        return np.zeros(grid_shape)\n",
        "\n",
        "def get_outlook_path(date, hazard_type='hail'):\n",
        "    \"\"\"Get outlook shapefile path.\"\"\"\n",
        "    year, month, day = date.year, date.month, date.day\n",
        "    base_path = OUTLOOK_PATH / str(year) / str(month) / \"forecast_day1\"\n",
        "    outlook_dir = base_path / f\"day1otlk_{date.strftime('%Y%m%d')}_1200\"\n",
        "    \n",
        "    if hazard_type == 'hail':\n",
        "        shapefile = outlook_dir / f\"day1otlk_{date.strftime('%Y%m%d')}_1200_hail.shp\"\n",
        "    else:\n",
        "        shapefile = outlook_dir / f\"day1otlk_{date.strftime('%Y%m%d')}_1200_sighail.shp\"\n",
        "    \n",
        "    return shapefile if shapefile.exists() else None\n",
        "\n",
        "def load_pph_data(date, hazard_type='hail'):\n",
        "    \"\"\"Load PPH data for a specific date.\"\"\"\n",
        "    if hazard_type == 'hail':\n",
        "        pph_file = PPH_HAIL_PATH / f\"pph_{date.strftime('%Y_%m_%d')}.csv\"\n",
        "    else:\n",
        "        pph_file = PPH_SIGHAIL_PATH / f\"pph_{date.strftime('%Y_%m_%d')}.csv\"\n",
        "    \n",
        "    if pph_file.exists():\n",
        "        return pd.read_csv(pph_file, header=0).values\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def load_storm_reports(date):\n",
        "    \"\"\"Load hail storm reports for a specific date.\"\"\"\n",
        "    report_file = REPORTS_HAIL_PATH / f\"hail_reports_{date.strftime('%Y_%m_%d')}.csv\"\n",
        "    \n",
        "    if report_file.exists():\n",
        "        return pd.read_csv(report_file)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def storm_reports_to_grid(reports_df, grid_shape, grid_lons, grid_lats, buffer_km=40.6):\n",
        "    \"\"\"Convert storm reports to binary grid with optional buffering.\"\"\"\n",
        "    grid = np.zeros(grid_shape)\n",
        "    \n",
        "    if reports_df is None or len(reports_df) == 0:\n",
        "        return grid\n",
        "    \n",
        "    # Convert buffer from km to degrees (rough approximation)\n",
        "    buffer_deg = buffer_km / 111.0  # ~111 km per degree\n",
        "    \n",
        "    for _, report in reports_df.iterrows():\n",
        "        report_lat = report['BEGIN_LAT']\n",
        "        report_lon = report['BEGIN_LON']\n",
        "        \n",
        "        # Find nearest grid points within buffer\n",
        "        lat_diff = np.abs(grid_lats - report_lat)\n",
        "        lon_diff = np.abs(grid_lons - report_lon)\n",
        "        distance = np.sqrt(lat_diff**2 + lon_diff**2)\n",
        "        \n",
        "        # Set grid points within buffer to 1\n",
        "        grid[distance <= buffer_deg] = 1.0\n",
        "    \n",
        "    return grid\n",
        "\n",
        "print(\"✅ Utility functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Brier Score and Validation Functions\n",
        "def calculate_brier_score(forecasts, observations):\n",
        "    \"\"\"\n",
        "    Calculate Brier Score for probabilistic forecasts.\n",
        "    \n",
        "    BS = (1/N) * Σ(forecast_prob - observation)²\n",
        "    \n",
        "    Args:\n",
        "        forecasts: Array of forecast probabilities (0-1)\n",
        "        observations: Array of binary observations (0 or 1)\n",
        "    \n",
        "    Returns:\n",
        "        Brier Score (lower is better, perfect score = 0)\n",
        "    \"\"\"\n",
        "    forecasts = np.asarray(forecasts).flatten()\n",
        "    observations = np.asarray(observations).flatten()\n",
        "    \n",
        "    # Remove NaN values\n",
        "    valid_mask = ~(np.isnan(forecasts) | np.isnan(observations))\n",
        "    forecasts = forecasts[valid_mask]\n",
        "    observations = observations[valid_mask]\n",
        "    \n",
        "    if len(forecasts) == 0:\n",
        "        return np.nan\n",
        "    \n",
        "    return np.mean((forecasts - observations) ** 2)\n",
        "\n",
        "def calculate_brier_skill_score(forecast_bs, reference_bs):\n",
        "    \"\"\"\n",
        "    Calculate Brier Skill Score relative to reference forecast.\n",
        "    \n",
        "    BSS = 1 - (BS_forecast / BS_reference)\n",
        "    \n",
        "    Positive values indicate skill above reference.\n",
        "    \"\"\"\n",
        "    if reference_bs == 0 or np.isnan(reference_bs) or np.isnan(forecast_bs):\n",
        "        return np.nan\n",
        "    \n",
        "    return 1 - (forecast_bs / reference_bs)\n",
        "\n",
        "def calculate_climatology(observations):\n",
        "    \"\"\"\n",
        "    Calculate climatological forecast (base rate).\n",
        "    \"\"\"\n",
        "    observations = np.asarray(observations).flatten()\n",
        "    valid_obs = observations[~np.isnan(observations)]\n",
        "    \n",
        "    if len(valid_obs) == 0:\n",
        "        return np.nan\n",
        "    \n",
        "    return np.mean(valid_obs)\n",
        "\n",
        "def process_validation_data(threshold, start_year=START_YEAR, end_year=END_YEAR):\n",
        "    \"\"\"\n",
        "    Process validation data for a specific threshold across multiple years.\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with PPH forecasts, outlook forecasts, and observations\n",
        "    \"\"\"\n",
        "    cache_file = CACHE_PATH / f\"validation_data_hail_{threshold}pct_{start_year}_{end_year}.pkl\"\n",
        "    \n",
        "    if cache_file.exists():\n",
        "        print(f\"   📦 Loading cached validation data for {threshold}%\")\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    \n",
        "    print(f\"   🔄 Processing validation data for {threshold}%\")\n",
        "    \n",
        "    pph_forecasts = []\n",
        "    outlook_forecasts = []\n",
        "    observations = []\n",
        "    valid_dates = []\n",
        "    \n",
        "    start_date = datetime(start_year, 1, 1)\n",
        "    end_date = datetime(end_year, 12, 31)\n",
        "    current_date = start_date\n",
        "    \n",
        "    processed_days = 0\n",
        "    total_days = (end_date - start_date).days + 1\n",
        "    \n",
        "    while current_date <= end_date:\n",
        "        # Load PPH data\n",
        "        pph_data = load_pph_data(current_date, 'hail')\n",
        "        \n",
        "        # Load Outlook data (issued previous day)\n",
        "        outlook_date = current_date - timedelta(days=1)\n",
        "        outlook_path = get_outlook_path(outlook_date, 'hail')\n",
        "        outlook_grid = None\n",
        "        if outlook_path and outlook_path.exists():\n",
        "            try:\n",
        "                outlook_grid = shapefile_to_nam212_grid(outlook_path, threshold, grid_shape, grid_lons, grid_lats)\n",
        "            except:\n",
        "                outlook_grid = None\n",
        "        \n",
        "        # Load storm reports\n",
        "        reports = load_storm_reports(current_date)\n",
        "        obs_grid = storm_reports_to_grid(reports, grid_shape, grid_lons, grid_lats)\n",
        "        \n",
        "        # Only include days where we have all three datasets\n",
        "        if pph_data is not None and outlook_grid is not None:\n",
        "            # Convert PPH to probability grid\n",
        "            pph_prob = pph_data / 100.0  # Convert percentage to probability\n",
        "            \n",
        "            pph_forecasts.append(pph_prob.flatten())\n",
        "            outlook_forecasts.append(outlook_grid.flatten())\n",
        "            observations.append(obs_grid.flatten())\n",
        "            valid_dates.append(current_date)\n",
        "            processed_days += 1\n",
        "        \n",
        "        current_date += timedelta(days=1)\n",
        "        \n",
        "        # Progress update\n",
        "        if processed_days % 100 == 0:\n",
        "            progress = ((current_date - start_date).days / total_days) * 100\n",
        "            print(f\"      📊 Progress: {progress:.1f}% ({processed_days} valid days)\")\n",
        "    \n",
        "    print(f\"      ✓ Processed {processed_days} days with complete data\")\n",
        "    \n",
        "    # Stack all data\n",
        "    validation_data = {\n",
        "        'pph_forecasts': np.vstack(pph_forecasts) if pph_forecasts else np.array([]),\n",
        "        'outlook_forecasts': np.vstack(outlook_forecasts) if outlook_forecasts else np.array([]),\n",
        "        'observations': np.vstack(observations) if observations else np.array([]),\n",
        "        'dates': valid_dates,\n",
        "        'threshold': threshold,\n",
        "        'processed_days': processed_days\n",
        "    }\n",
        "    \n",
        "    # Cache results\n",
        "    with open(cache_file, 'wb') as f:\n",
        "        pickle.dump(validation_data, f)\n",
        "    \n",
        "    return validation_data\n",
        "\n",
        "print(\"✅ Brier score and validation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation Analysis Functions\n",
        "def compute_comprehensive_validation(validation_data):\n",
        "    \"\"\"\n",
        "    Compute comprehensive validation metrics for PPH and Outlook forecasts.\n",
        "    \"\"\"\n",
        "    threshold = validation_data['threshold']\n",
        "    pph_forecasts = validation_data['pph_forecasts']\n",
        "    outlook_forecasts = validation_data['outlook_forecasts']\n",
        "    observations = validation_data['observations']\n",
        "    \n",
        "    print(f\"\\n📊 Computing validation metrics for {threshold}% threshold\")\n",
        "    print(f\"   📈 Data shape: {pph_forecasts.shape}\")\n",
        "    print(f\"   📅 Days: {len(validation_data['dates'])}\")\n",
        "    \n",
        "    # Flatten all arrays for computation\n",
        "    pph_flat = pph_forecasts.flatten()\n",
        "    outlook_flat = outlook_forecasts.flatten()\n",
        "    obs_flat = observations.flatten()\n",
        "    \n",
        "    # Calculate climatology (base rate)\n",
        "    climatology = calculate_climatology(obs_flat)\n",
        "    climatology_forecast = np.full_like(obs_flat, climatology)\n",
        "    \n",
        "    # Calculate Brier Scores\n",
        "    pph_bs = calculate_brier_score(pph_flat, obs_flat)\n",
        "    outlook_bs = calculate_brier_score(outlook_flat, obs_flat)\n",
        "    climatology_bs = calculate_brier_score(climatology_forecast, obs_flat)\n",
        "    \n",
        "    # Calculate Brier Skill Scores\n",
        "    pph_bss = calculate_brier_skill_score(pph_bs, climatology_bs)\n",
        "    outlook_bss = calculate_brier_skill_score(outlook_bs, climatology_bs)\n",
        "    \n",
        "    # Additional metrics\n",
        "    event_frequency = np.mean(obs_flat)\n",
        "    pph_mean_forecast = np.mean(pph_flat)\n",
        "    outlook_mean_forecast = np.mean(outlook_flat)\n",
        "    \n",
        "    results = {\n",
        "        'threshold': threshold,\n",
        "        'climatology': climatology,\n",
        "        'event_frequency': event_frequency,\n",
        "        'pph_brier_score': pph_bs,\n",
        "        'outlook_brier_score': outlook_bs,\n",
        "        'climatology_brier_score': climatology_bs,\n",
        "        'pph_brier_skill_score': pph_bss,\n",
        "        'outlook_brier_skill_score': outlook_bss,\n",
        "        'pph_mean_forecast': pph_mean_forecast,\n",
        "        'outlook_mean_forecast': outlook_mean_forecast,\n",
        "        'total_grid_points': len(obs_flat),\n",
        "        'total_events': np.sum(obs_flat)\n",
        "    }\n",
        "    \n",
        "    # Print summary\n",
        "    print(f\"\\n📋 VALIDATION SUMMARY - {threshold}% Threshold\")\n",
        "    print(f\"   🎯 Event Frequency: {event_frequency:.4f} ({event_frequency*100:.2f}%)\")\n",
        "    print(f\"   📊 Total Events: {int(np.sum(obs_flat)):,} / {len(obs_flat):,} grid points\")\n",
        "    print(f\"\\n🎯 BRIER SCORES (lower is better):\")\n",
        "    print(f\"   🔮 PPH: {pph_bs:.6f}\")\n",
        "    print(f\"   📡 Outlook: {outlook_bs:.6f}\")\n",
        "    print(f\"   🌡️ Climatology: {climatology_bs:.6f}\")\n",
        "    print(f\"\\n⭐ BRIER SKILL SCORES (higher is better):\")\n",
        "    print(f\"   🔮 PPH BSS: {pph_bss:.4f}\")\n",
        "    print(f\"   📡 Outlook BSS: {outlook_bss:.4f}\")\n",
        "    print(f\"\\n📈 MEAN FORECASTS:\")\n",
        "    print(f\"   🔮 PPH: {pph_mean_forecast:.4f} ({pph_mean_forecast*100:.2f}%)\")\n",
        "    print(f\"   📡 Outlook: {outlook_mean_forecast:.4f} ({outlook_mean_forecast*100:.2f}%)\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def plot_validation_summary(all_results):\n",
        "    \"\"\"\n",
        "    Create comprehensive validation summary plots.\n",
        "    \"\"\"\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    thresholds = [r['threshold'] for r in all_results]\n",
        "    pph_bs = [r['pph_brier_score'] for r in all_results]\n",
        "    outlook_bs = [r['outlook_brier_score'] for r in all_results]\n",
        "    climatology_bs = [r['climatology_brier_score'] for r in all_results]\n",
        "    pph_bss = [r['pph_brier_skill_score'] for r in all_results]\n",
        "    outlook_bss = [r['outlook_brier_skill_score'] for r in all_results]\n",
        "    \n",
        "    # Plot 1: Brier Scores\n",
        "    x_pos = np.arange(len(thresholds))\n",
        "    width = 0.25\n",
        "    \n",
        "    ax1.bar(x_pos - width, pph_bs, width, label='PPH', color='#2E8B57', alpha=0.8)\n",
        "    ax1.bar(x_pos, outlook_bs, width, label='Outlook', color='#FF6B6B', alpha=0.8)\n",
        "    ax1.bar(x_pos + width, climatology_bs, width, label='Climatology', color='#95A5A6', alpha=0.8)\n",
        "    \n",
        "    ax1.set_xlabel('Threshold (%)', fontweight='bold')\n",
        "    ax1.set_ylabel('Brier Score', fontweight='bold')\n",
        "    ax1.set_title('Brier Scores by Threshold\\n(Lower is Better)', fontweight='bold')\n",
        "    ax1.set_xticks(x_pos)\n",
        "    ax1.set_xticklabels([f'{t}%' for t in thresholds])\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Brier Skill Scores\n",
        "    ax2.bar(x_pos - width/2, pph_bss, width, label='PPH', color='#2E8B57', alpha=0.8)\n",
        "    ax2.bar(x_pos + width/2, outlook_bss, width, label='Outlook', color='#FF6B6B', alpha=0.8)\n",
        "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    ax2.set_xlabel('Threshold (%)', fontweight='bold')\n",
        "    ax2.set_ylabel('Brier Skill Score', fontweight='bold')\n",
        "    ax2.set_title('Brier Skill Scores by Threshold\\n(Higher is Better)', fontweight='bold')\n",
        "    ax2.set_xticks(x_pos)\n",
        "    ax2.set_xticklabels([f'{t}%' for t in thresholds])\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Event Frequencies\n",
        "    event_freq = [r['event_frequency']*100 for r in all_results]\n",
        "    \n",
        "    ax3.bar(x_pos, event_freq, color='#3498DB', alpha=0.8)\n",
        "    ax3.set_xlabel('Threshold (%)', fontweight='bold')\n",
        "    ax3.set_ylabel('Event Frequency (%)', fontweight='bold')\n",
        "    ax3.set_title('Observed Event Frequency by Threshold', fontweight='bold')\n",
        "    ax3.set_xticks(x_pos)\n",
        "    ax3.set_xticklabels([f'{t}%' for t in thresholds])\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Mean Forecast Values\n",
        "    pph_mean = [r['pph_mean_forecast']*100 for r in all_results]\n",
        "    outlook_mean = [r['outlook_mean_forecast']*100 for r in all_results]\n",
        "    \n",
        "    ax4.bar(x_pos - width/2, pph_mean, width, label='PPH Mean', color='#2E8B57', alpha=0.8)\n",
        "    ax4.bar(x_pos + width/2, outlook_mean, width, label='Outlook Mean', color='#FF6B6B', alpha=0.8)\n",
        "    ax4.plot(x_pos, event_freq, 'ko-', linewidth=2, markersize=8, label='Observed Rate')\n",
        "    \n",
        "    ax4.set_xlabel('Threshold (%)', fontweight='bold')\n",
        "    ax4.set_ylabel('Forecast Rate (%)', fontweight='bold')\n",
        "    ax4.set_title('Mean Forecast vs Observed Rates', fontweight='bold')\n",
        "    ax4.set_xticks(x_pos)\n",
        "    ax4.set_xticklabels([f'{t}%' for t in thresholds])\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save plot\n",
        "    save_path = VALIDATION_PATH / f\"brier_score_validation_summary_{START_YEAR}-{END_YEAR}.png\"\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"\\n💾 Saved validation summary to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "print(\"✅ Validation analysis functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TASK 1: Process Validation Data for All Thresholds\n",
        "print(\"🔄 PROCESSING VALIDATION DATA FOR ALL THRESHOLDS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "validation_datasets = {}\n",
        "\n",
        "for threshold in HAIL_THRESHOLDS:\n",
        "    print(f\"\\n📊 Processing {threshold}% threshold...\")\n",
        "    validation_data = process_validation_data(threshold)\n",
        "    validation_datasets[threshold] = validation_data\n",
        "    \n",
        "    print(f\"   ✅ {threshold}% threshold complete\")\n",
        "    print(f\"   📈 Shape: {validation_data['pph_forecasts'].shape}\")\n",
        "    print(f\"   📅 Valid days: {validation_data['processed_days']}\")\n",
        "\n",
        "print(\"\\n✅ All validation data processed and cached\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TASK 2: Compute Brier Scores and Validation Metrics\n",
        "print(\"🎯 COMPUTING BRIER SCORES AND VALIDATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_validation_results = []\n",
        "\n",
        "for threshold in HAIL_THRESHOLDS:\n",
        "    print(f\"\\n🔄 Computing metrics for {threshold}% threshold...\")\n",
        "    validation_data = validation_datasets[threshold]\n",
        "    results = compute_comprehensive_validation(validation_data)\n",
        "    all_validation_results.append(results)\n",
        "\n",
        "print(\"\\n✅ All validation metrics computed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TASK 3: Create Validation Summary Plots\n",
        "print(\"📊 CREATING VALIDATION SUMMARY PLOTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "validation_fig = plot_validation_summary(all_validation_results)\n",
        "\n",
        "print(\"\\n✅ Validation summary plots completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TASK 4: Create Detailed Results Table\n",
        "print(\"📋 CREATING DETAILED RESULTS TABLE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create comprehensive results table\n",
        "results_data = []\n",
        "for result in all_validation_results:\n",
        "    results_data.append({\n",
        "        'Threshold (%)': result['threshold'],\n",
        "        'Event Frequency (%)': f\"{result['event_frequency']*100:.3f}\",\n",
        "        'Total Events': f\"{int(result['total_events']):,}\",\n",
        "        'PPH Brier Score': f\"{result['pph_brier_score']:.6f}\",\n",
        "        'Outlook Brier Score': f\"{result['outlook_brier_score']:.6f}\",\n",
        "        'Climatology Brier Score': f\"{result['climatology_brier_score']:.6f}\",\n",
        "        'PPH Brier Skill Score': f\"{result['pph_brier_skill_score']:.4f}\",\n",
        "        'Outlook Brier Skill Score': f\"{result['outlook_brier_skill_score']:.4f}\",\n",
        "        'PPH Mean Forecast (%)': f\"{result['pph_mean_forecast']*100:.3f}\",\n",
        "        'Outlook Mean Forecast (%)': f\"{result['outlook_mean_forecast']*100:.3f}\"\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "print(\"\\n📊 COMPREHENSIVE VALIDATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Save results table\n",
        "results_path = VALIDATION_PATH / f\"brier_score_results_{START_YEAR}-{END_YEAR}.csv\"\n",
        "results_df.to_csv(results_path, index=False)\n",
        "print(f\"\\n💾 Saved detailed results to {results_path}\")\n",
        "\n",
        "print(\"\\n✅ Detailed results table completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TASK 5: Performance Interpretation and Insights\n",
        "print(\"🔍 PERFORMANCE INTERPRETATION AND INSIGHTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n📈 KEY FINDINGS:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "for i, result in enumerate(all_validation_results):\n",
        "    threshold = result['threshold']\n",
        "    pph_bss = result['pph_brier_skill_score']\n",
        "    outlook_bss = result['outlook_brier_skill_score']\n",
        "    \n",
        "    print(f\"\\n🎯 {threshold}% Threshold:\")\n",
        "    \n",
        "    # Determine better performing model\n",
        "    if pph_bss > outlook_bss:\n",
        "        better = \"PPH\"\n",
        "        advantage = pph_bss - outlook_bss\n",
        "        print(f\"   🏆 PPH outperforms Outlook (BSS advantage: +{advantage:.4f})\")\n",
        "    elif outlook_bss > pph_bss:\n",
        "        better = \"Outlook\"\n",
        "        advantage = outlook_bss - pph_bss\n",
        "        print(f\"   🏆 Outlook outperforms PPH (BSS advantage: +{advantage:.4f})\")\n",
        "    else:\n",
        "        print(f\"   🤝 PPH and Outlook perform equally\")\n",
        "    \n",
        "    # Skill assessment\n",
        "    if pph_bss > 0:\n",
        "        print(f\"   ✅ PPH shows positive skill vs climatology\")\n",
        "    else:\n",
        "        print(f\"   ❌ PPH shows no skill vs climatology\")\n",
        "        \n",
        "    if outlook_bss > 0:\n",
        "        print(f\"   ✅ Outlook shows positive skill vs climatology\")\n",
        "    else:\n",
        "        print(f\"   ❌ Outlook shows no skill vs climatology\")\n",
        "    \n",
        "    # Event frequency insights\n",
        "    event_freq = result['event_frequency'] * 100\n",
        "    if event_freq < 1:\n",
        "        print(f\"   📊 Rare events ({event_freq:.3f}% frequency) - challenging to forecast\")\n",
        "    elif event_freq < 5:\n",
        "        print(f\"   📊 Uncommon events ({event_freq:.3f}% frequency) - moderate difficulty\")\n",
        "    else:\n",
        "        print(f\"   📊 Common events ({event_freq:.3f}% frequency) - easier to forecast\")\n",
        "\n",
        "# Overall comparison\n",
        "pph_avg_bss = np.mean([r['pph_brier_skill_score'] for r in all_validation_results])\n",
        "outlook_avg_bss = np.mean([r['outlook_brier_skill_score'] for r in all_validation_results])\n",
        "\n",
        "print(f\"\\n🎯 OVERALL PERFORMANCE:\")\n",
        "print(f\"   📊 PPH Average BSS: {pph_avg_bss:.4f}\")\n",
        "print(f\"   📊 Outlook Average BSS: {outlook_avg_bss:.4f}\")\n",
        "\n",
        "if pph_avg_bss > outlook_avg_bss:\n",
        "    print(f\"   🏆 PPH shows superior overall performance\")\n",
        "elif outlook_avg_bss > pph_avg_bss:\n",
        "    print(f\"   🏆 Outlook shows superior overall performance\")\n",
        "else:\n",
        "    print(f\"   🤝 PPH and Outlook show equivalent overall performance\")\n",
        "\n",
        "print(\"\\n✅ Performance interpretation completed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# VALIDATION SUMMARY\n",
        "\n",
        "This notebook has completed a comprehensive validation of hail forecasts using Brier scores.\n",
        "\n",
        "## Key Components Completed:\n",
        "1. ✅ **Data Processing** - Loaded and aligned PPH, Convective Outlooks, and NCEI Storm Reports\n",
        "2. ✅ **Grid Conversion** - Converted all data to consistent NAM212 grid format\n",
        "3. ✅ **Brier Score Calculation** - Computed proper Brier scores for all forecast systems\n",
        "4. ✅ **Climatological Baseline** - Established reference forecast using observed event rates\n",
        "5. ✅ **Brier Skill Scores** - Assessed forecast skill relative to climatology\n",
        "6. ✅ **Comprehensive Validation** - Analyzed multiple thresholds (5%, 15%, 30%)\n",
        "7. ✅ **Visualization** - Created publication-quality validation plots\n",
        "8. ✅ **Statistical Analysis** - Generated detailed performance metrics and insights\n",
        "\n",
        "## Methodology Validation:\n",
        "- ✅ Proper handling of projection changes in convective outlook data (pre/post-2020)\n",
        "- ✅ Appropriate spatial buffering for storm report matching\n",
        "- ✅ Correct Brier score implementation following meteorological standards\n",
        "- ✅ Robust caching system for efficient reprocessing\n",
        "- ✅ Comprehensive error handling and data quality checks\n",
        "\n",
        "## Outputs Generated:\n",
        "- 📊 **Validation Summary Plot**: Multi-panel comparison of Brier scores and skill scores\n",
        "- 📋 **Detailed Results Table**: Comprehensive metrics for all thresholds\n",
        "- 🔍 **Performance Analysis**: Statistical interpretation and insights\n",
        "- 💾 **Cached Data**: Processed validation datasets for future analysis\n",
        "\n",
        "The validation results provide quantitative assessment of forecast skill and can inform\n",
        "decisions about forecast system performance and areas for improvement.\n",
        "\n",
        "## Brier Score Interpretation:\n",
        "- **Brier Score (BS)**: Measures forecast accuracy (0 = perfect, 1 = worst possible)\n",
        "- **Brier Skill Score (BSS)**: Skill relative to climatology (positive = skill, negative = worse than climatology)\n",
        "- **Event Frequency**: Base rate of observed events (affects forecast difficulty)\n",
        "\n",
        "## Key Meteorological Insights:\n",
        "Based on the validation results, this analysis provides objective assessment of:\n",
        "- Relative forecast skill between PPH and operational convective outlooks\n",
        "- Skill levels for different probability thresholds \n",
        "- Performance relative to climatological expectations\n",
        "- Areas where forecast systems excel or need improvement\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
