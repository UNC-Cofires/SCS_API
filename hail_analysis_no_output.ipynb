{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Comprehensive Hail Analysis: PPH vs Convective Outlooks\n",
    "\n",
    "This notebook provides a complete analysis comparing Practically Perfect Hindcasts (PPH) with SPC Convective Outlooks for hail events from 2010-2024.\n",
    "\n",
    "## Analysis Components:\n",
    "1. **Mean Annual Event Days Maps** - Side-by-side comparison with consistent color schemes\n",
    "2. **Area Coverage Time Series** - Monthly and yearly coverage trends  \n",
    "3. **Brier Score Analysis** - Quantitative forecast skill assessment\n",
    "4. **Performance Diagrams** - ROC-style analysis with multiple thresholds\n",
    "\n",
    "## Key Features:\n",
    "- ✅ Handles projection changes in convective outlook data (pre-2020 vs post-2020)\n",
    "- ✅ Standardized color schemes for easy comparison\n",
    "- ✅ Efficient caching system for large data processing\n",
    "- ✅ **SEPARATED INTO INDIVIDUAL CELLS FOR DEBUGGING**\n",
    "\n",
    "## Thresholds Analyzed:\n",
    "- **Hail**: 15%, 30%\n",
    "- **Significant Hail**: 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "from shapely.ops import unary_union, transform\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import binary_dilation\n",
    "import pyproj\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"📊 Matplotlib settings configured for high-quality plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Paths\n",
    "BASE_PATH = Path(\"/Users/jimnguyen/IRMII/SCS_API\")\n",
    "OUTLOOK_PATH = BASE_PATH / \"convective_outlooks_only1200z\"\n",
    "PPH_HAIL_PATH = BASE_PATH / \"PPH\" / \"NCEI_PPH\" / \"hail\"\n",
    "PPH_SIGHAIL_PATH = BASE_PATH / \"PPH\" / \"Sighail_PPH\" / \"sighail\"\n",
    "REPORTS_HAIL_PATH = BASE_PATH / \"NCEI_storm_reports\" / \"hail_filtered\"\n",
    "REPORTS_SIGHAIL_PATH = BASE_PATH / \"NCEI_storm_reports\" / \"sighail_filtered\"\n",
    "NAM212_PATH = BASE_PATH / \"PPH\" / \"nam212.nc\"\n",
    "\n",
    "# Output directory structure\n",
    "OUTPUT_PATH = BASE_PATH / \"analysis_outputs\"\n",
    "FIGURES_PATH = OUTPUT_PATH / \"figures\"\n",
    "MEAN_ANNUAL_PATH = FIGURES_PATH / \"mean_annual_event_days\"\n",
    "TIME_SERIES_PATH = FIGURES_PATH / \"time_series\"\n",
    "BRIER_SCORES_PATH = FIGURES_PATH / \"brier_scores\"\n",
    "PERFORMANCE_PATH = FIGURES_PATH / \"performance_diagrams\"\n",
    "\n",
    "START_YEAR = 2010\n",
    "END_YEAR = 2024\n",
    "HAIL_THRESHOLDS = [15, 30]\n",
    "SIGHAIL_THRESHOLDS = [10]\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "os.makedirs(MEAN_ANNUAL_PATH, exist_ok=True)\n",
    "os.makedirs(TIME_SERIES_PATH, exist_ok=True)\n",
    "os.makedirs(BRIER_SCORES_PATH, exist_ok=True)\n",
    "os.makedirs(PERFORMANCE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Configuration set for {START_YEAR}-{END_YEAR}\")\n",
    "print(f\"📁 Output directories created:\")\n",
    "print(f\"   📊 Figures: {FIGURES_PATH}\")\n",
    "print(f\"   🗺️ Mean Annual: {MEAN_ANNUAL_PATH}\")\n",
    "print(f\"   📈 Time Series: {TIME_SERIES_PATH}\")\n",
    "print(f\"   🎯 Brier Scores: {BRIER_SCORES_PATH}\")\n",
    "print(f\"   📋 Performance: {PERFORMANCE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NAM212 Grid\n",
    "nam212_ds = xr.open_dataset(NAM212_PATH)\n",
    "grid_lats = nam212_ds['gridlat_212'].values\n",
    "grid_lons = nam212_ds['gridlon_212'].values\n",
    "grid_shape = grid_lats.shape\n",
    "CELL_AREA_KM2 = 40.6 * 40.6\n",
    "\n",
    "print(f\"🗺️ NAM212 Grid: {grid_shape[0]} x {grid_shape[1]} = {grid_shape[0] * grid_shape[1]:,} cells\")\n",
    "print(f\"📏 Cell area: {CELL_AREA_KM2:,.1f} km² per cell\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapefile to NAM212 Grid Conversion\n",
    "def shapefile_to_nam212_grid(shapefile_path, threshold_value, grid_shape, grid_lons, grid_lats):\n",
    "    \"\"\"Convert shapefile polygons to NAM212 grid format with projection handling.\"\"\"\n",
    "    try:\n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "        grid = np.zeros(grid_shape)\n",
    "        \n",
    "        if len(gdf) == 0:\n",
    "            return grid\n",
    "        \n",
    "        # Filter by threshold using DN column\n",
    "        if 'DN' in gdf.columns:\n",
    "            threshold_gdf = gdf[gdf['DN'] == threshold_value].copy()\n",
    "        else:\n",
    "            threshold_rows = []\n",
    "            for idx, row in gdf.iterrows():\n",
    "                if str(threshold_value) in str(row.to_dict()):\n",
    "                    threshold_rows.append(row)\n",
    "            if threshold_rows:\n",
    "                threshold_gdf = gpd.GeoDataFrame(threshold_rows, crs=gdf.crs)\n",
    "            else:\n",
    "                return grid\n",
    "        \n",
    "        if len(threshold_gdf) == 0:\n",
    "            return grid\n",
    "        \n",
    "        # CRITICAL FIX: Check projection and reproject if needed\n",
    "        sample_geom = threshold_gdf.iloc[0].geometry\n",
    "        if sample_geom is not None:\n",
    "            if hasattr(sample_geom, 'exterior'):\n",
    "                x, y = list(sample_geom.exterior.coords)[0]\n",
    "            else:\n",
    "                x, y = list(sample_geom.geoms[0].exterior.coords)[0]\n",
    "            \n",
    "            # If coordinates > 180, it's projected (Lambert Conformal Conic)\n",
    "            if abs(x) > 180 or abs(y) > 90:\n",
    "                print(f\"   Reprojecting from {threshold_gdf.crs} to WGS84\")\n",
    "                threshold_gdf = threshold_gdf.to_crs('EPSG:4326')\n",
    "        \n",
    "        # Merge polygons and check grid points\n",
    "        all_geoms = [row.geometry for idx, row in threshold_gdf.iterrows() \n",
    "                    if row.geometry is not None and row.geometry.is_valid]\n",
    "        \n",
    "        if not all_geoms:\n",
    "            return grid\n",
    "            \n",
    "        merged_geom = unary_union(all_geoms)\n",
    "        if merged_geom.is_empty:\n",
    "            return grid\n",
    "            \n",
    "        minx, miny, maxx, maxy = merged_geom.bounds\n",
    "        \n",
    "        for i in range(grid_shape[0]):\n",
    "            for j in range(grid_shape[1]):\n",
    "                lon, lat = grid_lons[i, j], grid_lats[i, j]\n",
    "                if minx <= lon <= maxx and miny <= lat <= maxy:\n",
    "                    if merged_geom.contains(Point(lon, lat)):\n",
    "                        grid[i, j] = 1.0\n",
    "        \n",
    "        return grid\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Error processing {shapefile_path}: {e}\")\n",
    "        return np.zeros(grid_shape)\n",
    "\n",
    "print(\"✅ Projection handling function defined with critical fix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def get_outlook_path(date, hazard_type='hail'):\n",
    "    \"\"\"Get outlook shapefile path.\"\"\"\n",
    "    year, month, day = date.year, date.month, date.day\n",
    "    base_path = OUTLOOK_PATH / str(year) / str(month) / \"forecast_day1\"\n",
    "    outlook_dir = base_path / f\"day1otlk_{date.strftime('%Y%m%d')}_1200\"\n",
    "    \n",
    "    if hazard_type == 'hail':\n",
    "        shapefile = outlook_dir / f\"day1otlk_{date.strftime('%Y%m%d')}_1200_hail.shp\"\n",
    "    else:\n",
    "        shapefile = outlook_dir / f\"day1otlk_{date.strftime('%Y%m%d')}_1200_sighail.shp\"\n",
    "    \n",
    "    return shapefile if shapefile.exists() else None\n",
    "\n",
    "def load_pph_data(date, hazard_type='hail'):\n",
    "    \"\"\"Load PPH data for a specific date.\"\"\"\n",
    "    if hazard_type == 'hail':\n",
    "        pph_file = PPH_HAIL_PATH / f\"pph_{date.strftime('%Y_%m_%d')}.csv\"\n",
    "    else:\n",
    "        pph_file = PPH_SIGHAIL_PATH / f\"pph_{date.strftime('%Y_%m_%d')}.csv\"\n",
    "    \n",
    "    if pph_file.exists():\n",
    "        return pd.read_csv(pph_file, header=0).values\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_outlooks_for_year(hazard_type, threshold, year):\n",
    "    \"\"\"Process outlook data for a year with caching.\"\"\"\n",
    "    cache_file = f\"cache/outlook_{hazard_type}_{threshold}_{year}.pkl\"\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"   📦 Loading cached outlook data for {year}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"   🔄 Processing {hazard_type} {threshold}% outlooks for {year}\")\n",
    "    yearly_grid = np.zeros(grid_shape)\n",
    "    \n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    days_processed = 0\n",
    "    while current_date <= end_date:\n",
    "        # CORRECTED: Use outlook issued on previous day (valid during current_date)\n",
    "        outlook_date = current_date - timedelta(days=1)\n",
    "        outlook_path = get_outlook_path(outlook_date, hazard_type)\n",
    "        if outlook_path and outlook_path.exists():\n",
    "            try:\n",
    "                grid = shapefile_to_nam212_grid(outlook_path, threshold, grid_shape, grid_lons, grid_lats)\n",
    "                if np.any(grid > 0):\n",
    "                    yearly_grid += grid\n",
    "                    days_processed += 1\n",
    "            except:\n",
    "                pass\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    print(f\"      ✓ Processed {days_processed} days with {threshold}% outlook\")\n",
    "    \n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(yearly_grid, f)\n",
    "    \n",
    "    return yearly_grid\n",
    "\n",
    "def process_pph_for_year(hazard_type, threshold, year):\n",
    "    \"\"\"Process PPH data for a year with caching.\"\"\"\n",
    "    cache_file = f\"cache/pph_{hazard_type}_{threshold}_{year}.pkl\"\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"   📦 Loading cached PPH data for {year}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"   🔄 Processing {hazard_type} {threshold}% PPH for {year}\")\n",
    "    yearly_grid = np.zeros(grid_shape)\n",
    "    \n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    days_processed = 0\n",
    "    while current_date <= end_date:\n",
    "        pph_data = load_pph_data(current_date, hazard_type)\n",
    "        if pph_data is not None:\n",
    "            yearly_grid += (pph_data >= threshold/100.0).astype(float)\n",
    "            days_processed += 1\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    print(f\"      ✓ Processed {days_processed} days with PPH data\")\n",
    "    \n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(yearly_grid, f)\n",
    "    \n",
    "    return yearly_grid\n",
    "\n",
    "print(\"✅ Utility functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Functions\n",
    "def get_color_scheme(hazard_type, threshold):\n",
    "    \"\"\"Get standardized color scheme for plots.\"\"\"\n",
    "    if hazard_type == 'hail':\n",
    "        if threshold == 15:\n",
    "            colors = ['white', '#e6ffe6', '#b3ffb3', '#66ff66', '#33cc33', '#009900', '#006600', '#003300']\n",
    "            levels = [0.025, 1, 4, 8, 12, 16, 20, 24]\n",
    "        elif threshold == 30:\n",
    "            colors = ['white', '#ffe6cc', '#ffcc99', '#ff9966', '#ff6633', '#ff3300', '#cc0000', '#660000']\n",
    "            levels = [0.025, 1, 3, 6, 10, 15, 20, 30]\n",
    "    else:  # sighail\n",
    "        colors = ['white', '#e6f3ff', '#b3d9ff', '#66b3ff', '#3399ff', '#0066cc', '#003d7a', '#001a4d']\n",
    "        levels = [0.025, 1, 2, 4, 6, 8, 10, 12]\n",
    "    \n",
    "    cmap = LinearSegmentedColormap.from_list(f'{hazard_type}_{threshold}', colors, N=256)\n",
    "    norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "    return cmap, norm, levels\n",
    "\n",
    "def plot_mean_annual_event_days(pph_data, outlook_data, hazard_type, threshold, custom_save_path=None):\n",
    "    \"\"\"Create side-by-side comparison plots with organized output structure.\"\"\"\n",
    "    cmap, norm, levels = get_color_scheme(hazard_type, threshold)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), \n",
    "                                   subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # PPH plot\n",
    "    im1 = ax1.contourf(grid_lons, grid_lats, pph_data, levels=levels, cmap=cmap, norm=norm, \n",
    "                       transform=ccrs.PlateCarree(), extend='max')\n",
    "    ax1.add_feature(cfeature.STATES, linewidth=0.5, edgecolor='black')\n",
    "    ax1.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
    "    ax1.add_feature(cfeature.BORDERS, linewidth=0.8)\n",
    "    ax1.set_extent([-130, -65, 20, 50], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    max_idx = np.unravel_index(np.argmax(pph_data), pph_data.shape)\n",
    "    max_val = pph_data[max_idx]\n",
    "    max_lon, max_lat = grid_lons[max_idx], grid_lats[max_idx]\n",
    "    ax1.plot(max_lon, max_lat, 'k+', markersize=15, markeredgewidth=3, transform=ccrs.PlateCarree())\n",
    "    ax1.set_title(f'PPH {threshold}% {hazard_type.capitalize()} ({START_YEAR}-{END_YEAR})\\nMax: {max_val:.1f} days', \n",
    "                  fontsize=16, weight='bold')\n",
    "    \n",
    "    # Outlook plot\n",
    "    im2 = ax2.contourf(grid_lons, grid_lats, outlook_data, levels=levels, cmap=cmap, norm=norm, \n",
    "                       transform=ccrs.PlateCarree(), extend='max')\n",
    "    ax2.add_feature(cfeature.STATES, linewidth=0.5, edgecolor='black')\n",
    "    ax2.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
    "    ax2.add_feature(cfeature.BORDERS, linewidth=0.8)\n",
    "    ax2.set_extent([-130, -65, 20, 50], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    max_idx = np.unravel_index(np.argmax(outlook_data), outlook_data.shape)\n",
    "    max_val = outlook_data[max_idx]\n",
    "    max_lon, max_lat = grid_lons[max_idx], grid_lats[max_idx]\n",
    "    ax2.plot(max_lon, max_lat, 'k+', markersize=15, markeredgewidth=3, transform=ccrs.PlateCarree())\n",
    "    ax2.set_title(f'Convective Outlook {threshold}% {hazard_type.capitalize()} ({START_YEAR}-{END_YEAR})\\nMax: {max_val:.1f} days', \n",
    "                  fontsize=16, weight='bold')\n",
    "    \n",
    "    # Shared colorbar\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im1, cax=cbar_ax, orientation='vertical')\n",
    "    cbar.set_label('Mean Annual Event Days', fontsize=14)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Organized save path\n",
    "    if custom_save_path:\n",
    "        save_path = custom_save_path\n",
    "    else:\n",
    "        # Create organized filename and path\n",
    "        filename = f\"mean_annual_{hazard_type}_{threshold}pct_{START_YEAR}-{END_YEAR}.png\"\n",
    "        save_path = MEAN_ANNUAL_PATH / filename\n",
    "    \n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"💾 Saved plot to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Plotting functions defined\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TASK 1: Mean Annual Event Days Analysis\n",
    "\n",
    "Run the cells below to process and plot mean annual event days for each threshold.  \n",
    "Each threshold is processed independently - you can run specific thresholds as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 1A: Process HAIL 15% Data\n",
    "print(\"🔄 PROCESSING HAIL 15%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Process outlooks\n",
    "hail_15_outlook_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_outlooks_for_year('hail', 15, year)\n",
    "    hail_15_outlook_annual.append(grid)\n",
    "hail_15_outlook_mean = np.mean(hail_15_outlook_annual, axis=0)\n",
    "\n",
    "# Process PPH\n",
    "hail_15_pph_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_pph_for_year('hail', 15, year)\n",
    "    hail_15_pph_annual.append(grid)\n",
    "hail_15_pph_mean = np.mean(hail_15_pph_annual, axis=0)\n",
    "\n",
    "print(f\"✅ HAIL 15% Complete\")\n",
    "print(f\"   📊 PPH Max: {np.max(hail_15_pph_mean):.1f} days\")\n",
    "print(f\"   📊 Outlook Max: {np.max(hail_15_outlook_mean):.1f} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1A: Plot HAIL 15% Results\n",
    "print(\"📊 PLOTTING HAIL 15% COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plot_mean_annual_event_days(hail_15_pph_mean, hail_15_outlook_mean, 'hail', 15)\n",
    "\n",
    "print(f\"✅ HAIL 15% plot completed and saved to organized directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 1B: Process HAIL 30% Data\n",
    "print(\"🔄 PROCESSING HAIL 30%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Process outlooks\n",
    "hail_30_outlook_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_outlooks_for_year('hail', 30, year)\n",
    "    hail_30_outlook_annual.append(grid)\n",
    "hail_30_outlook_mean = np.mean(hail_30_outlook_annual, axis=0)\n",
    "\n",
    "# Process PPH\n",
    "hail_30_pph_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_pph_for_year('hail', 30, year)\n",
    "    hail_30_pph_annual.append(grid)\n",
    "hail_30_pph_mean = np.mean(hail_30_pph_annual, axis=0)\n",
    "\n",
    "print(f\"✅ HAIL 30% Complete\")\n",
    "print(f\"   📊 PPH Max: {np.max(hail_30_pph_mean):.1f} days\")\n",
    "print(f\"   📊 Outlook Max: {np.max(hail_30_outlook_mean):.1f} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1B: Plot HAIL 30% Results\n",
    "print(\"📊 PLOTTING HAIL 30% COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plot_mean_annual_event_days(hail_30_pph_mean, hail_30_outlook_mean, 'hail', 30)\n",
    "\n",
    "print(f\"✅ HAIL 30% plot completed and saved to organized directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 1C: Process SIGHAIL 10% Data\n",
    "print(\"🔄 PROCESSING SIGHAIL 10%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Process outlooks\n",
    "sighail_10_outlook_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_outlooks_for_year('sighail', 10, year)\n",
    "    sighail_10_outlook_annual.append(grid)\n",
    "sighail_10_outlook_mean = np.mean(sighail_10_outlook_annual, axis=0)\n",
    "\n",
    "# Process PPH\n",
    "sighail_10_pph_annual = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    grid = process_pph_for_year('sighail', 10, year)\n",
    "    sighail_10_pph_annual.append(grid)\n",
    "sighail_10_pph_mean = np.mean(sighail_10_pph_annual, axis=0)\n",
    "\n",
    "print(f\"✅ SIGHAIL 10% Complete\")\n",
    "print(f\"   📊 PPH Max: {np.max(sighail_10_pph_mean):.1f} days\")\n",
    "print(f\"   📊 Outlook Max: {np.max(sighail_10_outlook_mean):.1f} days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1C: Plot SIGHAIL 10% Results\n",
    "print(\"📊 PLOTTING SIGHAIL 10% COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "plot_mean_annual_event_days(sighail_10_pph_mean, sighail_10_outlook_mean, 'sighail', 10)\n",
    "\n",
    "print(f\"✅ SIGHAIL 10% plot completed and saved to organized directory\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TASK 2: Area Coverage Time Series Analysis\n",
    "\n",
    "Analysis of temporal trends in forecast area coverage for all hazard types and thresholds.\n",
    "This section generates monthly and yearly time series plots comparing PPH vs Convective Outlooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area Coverage Time Series Functions\n",
    "def calculate_area_coverage(grid_data):\n",
    "    \"\"\"Calculate area coverage in km² from grid data.\"\"\"\n",
    "    return np.sum(grid_data > 0) * CELL_AREA_KM2\n",
    "\n",
    "def process_monthly_coverage(hazard_type, threshold, data_type='pph'):\n",
    "    \"\"\"Process monthly area coverage for a hazard type and threshold.\"\"\"\n",
    "    cache_file = f\"cache/monthly_coverage_{data_type}_{hazard_type}_{threshold}_{START_YEAR}_{END_YEAR}.pkl\"\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"   📦 Loading cached monthly {data_type} coverage data\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"   🔄 Processing monthly {data_type} {hazard_type} {threshold}% coverage\")\n",
    "    \n",
    "    monthly_coverage = []\n",
    "    date_labels = []\n",
    "    \n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        for month in range(1, 13):\n",
    "            month_coverage = 0\n",
    "            days_in_month = 0\n",
    "            \n",
    "            # Get days in month\n",
    "            if month == 12:\n",
    "                next_month = datetime(year + 1, 1, 1)\n",
    "            else:\n",
    "                next_month = datetime(year, month + 1, 1)\n",
    "            current_date = datetime(year, month, 1)\n",
    "            \n",
    "            while current_date < next_month:\n",
    "                if data_type == 'pph':\n",
    "                    data = load_pph_data(current_date, hazard_type)\n",
    "                    if data is not None:\n",
    "                        grid = (data >= threshold/100.0).astype(float)\n",
    "                        month_coverage += calculate_area_coverage(grid)\n",
    "                        days_in_month += 1\n",
    "                else:  # outlook\n",
    "                    outlook_path = get_outlook_path(current_date, hazard_type)\n",
    "                    if outlook_path and outlook_path.exists():\n",
    "                        try:\n",
    "                            grid = shapefile_to_nam212_grid(outlook_path, threshold, grid_shape, grid_lons, grid_lats)\n",
    "                            month_coverage += calculate_area_coverage(grid)\n",
    "                            days_in_month += 1\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                current_date += timedelta(days=1)\n",
    "            \n",
    "            # Average daily coverage for the month\n",
    "            avg_coverage = month_coverage / days_in_month if days_in_month > 0 else 0\n",
    "            monthly_coverage.append(avg_coverage)\n",
    "            date_labels.append(f\"{year}-{month:02d}\")\n",
    "    \n",
    "    result = {'coverage': monthly_coverage, 'dates': date_labels}\n",
    "    \n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_yearly_coverage(hazard_type, threshold, data_type='pph'):\n",
    "    \"\"\"Process yearly area coverage for a hazard type and threshold.\"\"\"\n",
    "    cache_file = f\"cache/yearly_coverage_{data_type}_{hazard_type}_{threshold}_{START_YEAR}_{END_YEAR}.pkl\"\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"   📦 Loading cached yearly {data_type} coverage data\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"   🔄 Processing yearly {data_type} {hazard_type} {threshold}% coverage\")\n",
    "    \n",
    "    yearly_coverage = []\n",
    "    \n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        year_coverage = 0\n",
    "        days_in_year = 0\n",
    "        \n",
    "        start_date = datetime(year, 1, 1)\n",
    "        end_date = datetime(year, 12, 31)\n",
    "        current_date = start_date\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            if data_type == 'pph':\n",
    "                data = load_pph_data(current_date, hazard_type)\n",
    "                if data is not None:\n",
    "                    grid = (data >= threshold/100.0).astype(float)\n",
    "                    year_coverage += calculate_area_coverage(grid)\n",
    "                    days_in_year += 1\n",
    "            else:  # outlook\n",
    "                outlook_path = get_outlook_path(current_date, hazard_type)\n",
    "                if outlook_path and outlook_path.exists():\n",
    "                    try:\n",
    "                        grid = shapefile_to_nam212_grid(outlook_path, threshold, grid_shape, grid_lons, grid_lats)\n",
    "                        year_coverage += calculate_area_coverage(grid)\n",
    "                        days_in_year += 1\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        # Average daily coverage for the year\n",
    "        avg_coverage = year_coverage / days_in_year if days_in_year > 0 else 0\n",
    "        yearly_coverage.append(avg_coverage)\n",
    "    \n",
    "    result = {'coverage': yearly_coverage, 'years': list(range(START_YEAR, END_YEAR + 1))}\n",
    "    \n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"✅ Area coverage time series functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plotting Functions\n",
    "def plot_area_coverage_timeseries(time_type='monthly'):\n",
    "    \"\"\"Create comprehensive time series plots for area coverage.\"\"\"\n",
    "    \n",
    "    # Define hazard configurations for 3 types\n",
    "    hazard_configs = [\n",
    "        {'hazard': 'hail', 'threshold': 15, 'pph_color': '#2E8B57', 'outlook_color': '#90EE90'},\n",
    "        {'hazard': 'hail', 'threshold': 30, 'pph_color': '#B22222', 'outlook_color': '#FFA07A'},\n",
    "        {'hazard': 'sighail', 'threshold': 10, 'pph_color': '#4169E1', 'outlook_color': '#87CEEB'}\n",
    "    ]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    max_coverage = 0\n",
    "    \n",
    "    for config in hazard_configs:\n",
    "        hazard = config['hazard']\n",
    "        threshold = config['threshold']\n",
    "        pph_color = config['pph_color']\n",
    "        outlook_color = config['outlook_color']\n",
    "        \n",
    "        # Process data\n",
    "        if time_type == 'monthly':\n",
    "            pph_data = process_monthly_coverage(hazard, threshold, 'pph')\n",
    "            outlook_data = process_monthly_coverage(hazard, threshold, 'outlook')\n",
    "            x_data = [datetime.strptime(date, '%Y-%m') for date in pph_data['dates']]\n",
    "        else:  # yearly\n",
    "            pph_data = process_yearly_coverage(hazard, threshold, 'pph')\n",
    "            outlook_data = process_yearly_coverage(hazard, threshold, 'outlook')\n",
    "            x_data = pph_data['years']\n",
    "        \n",
    "        # Plot PPH line (solid)\n",
    "        pph_label = f\"PPH {hazard.capitalize()} {threshold}%\"\n",
    "        ax.plot(x_data, pph_data['coverage'], color=pph_color, linestyle='-', \n",
    "               linewidth=2.5, marker='o', markersize=4, label=pph_label, alpha=0.8)\n",
    "        \n",
    "        # Plot Outlook line (dashed)\n",
    "        outlook_label = f\"Outlook {hazard.capitalize()} {threshold}%\"\n",
    "        ax.plot(x_data, outlook_data['coverage'], color=outlook_color, linestyle='--', \n",
    "               linewidth=2.5, marker='s', markersize=4, label=outlook_label, alpha=0.8)\n",
    "        \n",
    "        # Track max coverage\n",
    "        max_coverage = max(max_coverage, max(pph_data['coverage']), max(outlook_data['coverage']))\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('Area Coverage (km²)', fontsize=14, weight='bold')\n",
    "    ax.set_title(f'{time_type.capitalize()} Area Coverage: PPH vs Convective Outlooks ({START_YEAR}-{END_YEAR})', \n",
    "                fontsize=16, weight='bold', pad=20)\n",
    "    \n",
    "    if time_type == 'monthly':\n",
    "        ax.set_xlabel('Month-Year', fontsize=14, weight='bold')\n",
    "        # Format x-axis for monthly data\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        ax.xaxis.set_minor_locator(mdates.MonthLocator([1, 7]))\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax.set_xlabel('Year', fontsize=14, weight='bold')\n",
    "        ax.set_xticks(range(START_YEAR, END_YEAR + 1, 2))\n",
    "    \n",
    "    # Grid and legend\n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.legend(loc='upper left', frameon=True, fancybox=True, shadow=True, \n",
    "             ncol=2, fontsize=11, bbox_to_anchor=(0.02, 0.98))\n",
    "    \n",
    "    # Y-axis formatting\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
    "    ax.set_ylim(0, max_coverage * 1.1)\n",
    "    \n",
    "    # Styling\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.2)\n",
    "    ax.spines['bottom'].set_linewidth(1.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    filename = f\"area_coverage_{time_type}_{START_YEAR}-{END_YEAR}.png\"\n",
    "    save_path = TIME_SERIES_PATH / filename\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"💾 Saved {time_type} plot to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Time series plotting functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Individual Comparison Plotting Function\n",
    "def plot_individual_comparison_enhanced(hazard_type, threshold, time_type='monthly'):\n",
    "    \"\"\"Create enhanced individual comparison plots for specific hazard type and threshold.\"\"\"\n",
    "    \n",
    "    # Process data based on time type\n",
    "    if time_type == 'monthly':\n",
    "        pph_data = process_monthly_coverage(hazard_type, threshold, 'pph')\n",
    "        outlook_data = process_monthly_coverage(hazard_type, threshold, 'outlook')\n",
    "        x_data = [datetime.strptime(date, '%Y-%m') for date in pph_data['dates']]\n",
    "        x_label = 'Month-Year'\n",
    "        title_period = f'{time_type.capitalize()} Comparison'\n",
    "    else:  # yearly\n",
    "        pph_data = process_yearly_coverage(hazard_type, threshold, 'pph')\n",
    "        outlook_data = process_yearly_coverage(hazard_type, threshold, 'outlook')\n",
    "        x_data = pph_data['years']\n",
    "        x_label = 'Year'\n",
    "        title_period = f'{time_type.capitalize()} Comparison'\n",
    "    \n",
    "    # Create enhanced plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Color scheme based on hazard type\n",
    "    if hazard_type == 'hail' and threshold == 15:\n",
    "        pph_color = '#2E8B57'  # Sea Green\n",
    "        outlook_color = '#90EE90'  # Light Green\n",
    "    elif hazard_type == 'hail' and threshold == 30:\n",
    "        pph_color = '#B22222'  # Fire Brick\n",
    "        outlook_color = '#FFA07A'  # Light Salmon\n",
    "    else:  # sighail\n",
    "        pph_color = '#4169E1'  # Royal Blue\n",
    "        outlook_color = '#87CEEB'  # Sky Blue\n",
    "    \n",
    "    # Plot PPH data (solid line with circles)\n",
    "    ax.plot(x_data, pph_data['coverage'], color=pph_color, linestyle='-', \n",
    "           linewidth=3, marker='o', markersize=6, label=f'PPH {hazard_type.capitalize()} {threshold}%', \n",
    "           alpha=0.9, markerfacecolor='white', markeredgewidth=2)\n",
    "    \n",
    "    # Plot Outlook data (dashed line with squares)\n",
    "    ax.plot(x_data, outlook_data['coverage'], color=outlook_color, linestyle='--', \n",
    "           linewidth=3, marker='s', markersize=6, label=f'Convective Outlook {hazard_type.capitalize()} {threshold}%', \n",
    "           alpha=0.9, markerfacecolor='white', markeredgewidth=2)\n",
    "    \n",
    "    # Enhanced styling\n",
    "    ax.set_ylabel('Area Coverage (km²)', fontsize=14, weight='bold')\n",
    "    ax.set_xlabel(x_label, fontsize=14, weight='bold')\n",
    "    ax.set_title(f'{title_period}: {hazard_type.capitalize()} {threshold}% Coverage\\n'\n",
    "                f'PPH vs Convective Outlooks ({START_YEAR}-{END_YEAR})', \n",
    "                fontsize=16, weight='bold', pad=20)\n",
    "    \n",
    "    # Format axes\n",
    "    if time_type == 'monthly':\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        ax.xaxis.set_minor_locator(mdates.MonthLocator([1, 7]))\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax.set_xticks(range(START_YEAR, END_YEAR + 1, 2))\n",
    "    \n",
    "    # Enhanced grid and legend\n",
    "    ax.grid(True, alpha=0.4, linestyle='-', linewidth=0.8)\n",
    "    ax.legend(loc='upper left', frameon=True, fancybox=True, shadow=True, \n",
    "             fontsize=12, framealpha=0.9)\n",
    "    \n",
    "    # Y-axis formatting\n",
    "    max_coverage = max(max(pph_data['coverage']), max(outlook_data['coverage']))\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1000:.0f}K'))\n",
    "    ax.set_ylim(0, max_coverage * 1.1)\n",
    "    \n",
    "    # Professional styling\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    \n",
    "    # Add summary statistics box\n",
    "    pph_mean = np.mean(pph_data['coverage'])\n",
    "    outlook_mean = np.mean(outlook_data['coverage'])\n",
    "    \n",
    "    stats_text = f'Mean Coverage:\\nPPH: {pph_mean/1000:.1f}K km²\\nOutlook: {outlook_mean/1000:.1f}K km²'\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot to organized directory\n",
    "    filename = f\"individual_{time_type}_{hazard_type}_{threshold}pct_{START_YEAR}-{END_YEAR}.png\"\n",
    "    save_path = TIME_SERIES_PATH / filename\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"💾 Saved {hazard_type} {threshold}% {time_type} plot to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Enhanced individual comparison plotting function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 2C\n",
    "print(\"📊 GENERATING ENHANCED INDIVIDUAL MONTHLY COMPARISON PLOTS\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "enhanced_hazard_configs = [\n",
    "    ('hail', 15),\n",
    "    ('hail', 30), \n",
    "    ('sighail', 10),\n",
    "]\n",
    "\n",
    "for hazard_type, threshold in enhanced_hazard_configs:\n",
    "    print(f\"\\n🔄 Processing {hazard_type.upper()} {threshold}% monthly comparison...\")\n",
    "    plot_individual_comparison_enhanced(hazard_type, threshold, 'monthly')\n",
    "\n",
    "print(\"\\n✅ All enhanced individual monthly comparison plots completed and saved to organized directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 2D Enhanced: Individual Yearly Comparison Plots \n",
    "print(\"📈 GENERATING ENHANCED INDIVIDUAL YEARLY COMPARISON PLOTS\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Generate enhanced individual yearly plots for each hazard type/threshold\n",
    "for hazard_type, threshold in enhanced_hazard_configs:\n",
    "    print(f\"\\n🔄 Processing {hazard_type.upper()} {threshold}% yearly comparison...\")\n",
    "    plot_individual_comparison_enhanced(hazard_type, threshold, 'yearly')\n",
    "\n",
    "print(\"\\n✅ All enhanced individual yearly comparison plots completed and saved to organized directory\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# TASK 3: Daily Overlap Analysis (Jaccard Index)\n",
    "\n",
    "Analysis of daily spatial overlap between PPH and Convective Outlooks using Intersection over Union (IoU).\n",
    "This section calculates the fraction of overlap using the formula:\n",
    "**Overlap Fraction = Overlap Area / (PPH Area + Outlook Area - Overlap Area)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Overlap Analysis Functions\n",
    "def calculate_jaccard_index(grid1, grid2):\n",
    "    \"\"\"\n",
    "    Calculate Jaccard Index (Intersection over Union) between two binary grids.\n",
    "    \n",
    "    Jaccard = |A ∩ B| / |A ∪ B| = Overlap / (Area1 + Area2 - Overlap)\n",
    "    \"\"\"\n",
    "    # Convert to binary masks\n",
    "    mask1 = grid1 > 0\n",
    "    mask2 = grid2 > 0\n",
    "    \n",
    "    # Calculate areas in terms of grid cells\n",
    "    area1 = np.sum(mask1)\n",
    "    area2 = np.sum(mask2)\n",
    "    overlap = np.sum(mask1 & mask2)\n",
    "    \n",
    "    # Jaccard Index formula\n",
    "    union = area1 + area2 - overlap\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0  # Both grids are empty\n",
    "    \n",
    "    return overlap / union\n",
    "\n",
    "def process_daily_overlap_timeseries(pph_hazard, pph_threshold, outlook_hazard, outlook_threshold):\n",
    "    \"\"\"\n",
    "    Calculate daily overlap timeseries between PPH and convective outlook.\n",
    "    \n",
    "    Returns a list of tuples: (date, jaccard_index)\n",
    "    \"\"\"\n",
    "    cache_file = f\"cache/overlap_timeseries_{pph_hazard}_{outlook_hazard}_{pph_threshold}_{outlook_threshold}_{START_YEAR}_{END_YEAR}.pkl\"\n",
    "    \n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"   📦 Loading cached overlap data for {pph_hazard} {pph_threshold}% vs {outlook_hazard} {outlook_threshold}%\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    print(f\"   🔄 Processing daily overlap: {pph_hazard} {pph_threshold}% PPH vs {outlook_hazard} {outlook_threshold}% Outlook\")\n",
    "    \n",
    "    daily_overlaps = []\n",
    "    \n",
    "    # Process each day from 2010-2024\n",
    "    start_date = datetime(START_YEAR, 1, 1)\n",
    "    end_date = datetime(END_YEAR, 12, 31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    processed_days = 0\n",
    "    while current_date <= end_date:\n",
    "        # Load PPH data\n",
    "        pph_data = load_pph_data(current_date, pph_hazard)\n",
    "        pph_grid = None\n",
    "        if pph_data is not None:\n",
    "            pph_grid = (pph_data >= pph_threshold/100.0).astype(float)\n",
    "        \n",
    "        # Load Outlook data\n",
    "        outlook_path = get_outlook_path(current_date, outlook_hazard)\n",
    "        outlook_grid = None\n",
    "        if outlook_path and outlook_path.exists():\n",
    "            try:\n",
    "                outlook_grid = shapefile_to_nam212_grid(outlook_path, outlook_threshold, grid_shape, grid_lons, grid_lats)\n",
    "            except:\n",
    "                outlook_grid = None\n",
    "        \n",
    "        # Calculate overlap if both datasets are available\n",
    "        jaccard_index = np.nan\n",
    "        if pph_grid is not None and outlook_grid is not None:\n",
    "            jaccard_index = calculate_jaccard_index(pph_grid, outlook_grid)\n",
    "            processed_days += 1\n",
    "        \n",
    "        daily_overlaps.append((current_date, jaccard_index))\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    print(f\"      ✓ Processed {processed_days} days with both PPH and Outlook data\")\n",
    "    \n",
    "    # Cache results\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(daily_overlaps, f)\n",
    "    \n",
    "    return daily_overlaps\n",
    "\n",
    "def plot_overlap_timeseries(pph_hazard, pph_threshold, outlook_hazard, outlook_threshold):\n",
    "    \"\"\"\n",
    "    Create time series plot of daily overlap fractions.\n",
    "    \"\"\"\n",
    "    # Get overlap data\n",
    "    daily_data = process_daily_overlap_timeseries(pph_hazard, pph_threshold, outlook_hazard, outlook_threshold)\n",
    "    \n",
    "    # Extract dates and values, filtering out NaN values\n",
    "    dates = []\n",
    "    values = []\n",
    "    for date, jaccard in daily_data:\n",
    "        if not np.isnan(jaccard):\n",
    "            dates.append(date)\n",
    "            values.append(jaccard * 100)  # Convert to percentage\n",
    "    \n",
    "    if len(dates) == 0:\n",
    "        print(f\"   ⚠️ No valid data for {pph_hazard} {pph_threshold}% vs {outlook_hazard} {outlook_threshold}%\")\n",
    "        return None\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    # Color scheme based on hazard type\n",
    "    if pph_hazard == 'hail':\n",
    "        color = '#2E8B57' if pph_threshold == 15 else '#B22222'\n",
    "    else:  # sighail\n",
    "        color = '#4169E1'\n",
    "    \n",
    "    # Plot time series\n",
    "    ax.plot(dates, values, color=color, linewidth=1.5, alpha=0.7, marker='.', markersize=2)\n",
    "    \n",
    "    # Add rolling mean for trend visualization\n",
    "    if len(values) > 30:\n",
    "        values_series = pd.Series(values, index=dates)\n",
    "        rolling_mean = values_series.rolling(window=30, center=True).mean()\n",
    "        ax.plot(dates, rolling_mean, color=color, linewidth=3, alpha=0.9, \n",
    "               label=f'30-day rolling mean')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('Overlap Fraction (%)', fontsize=14, weight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=14, weight='bold')\n",
    "    \n",
    "    title = f'Daily Overlap: {pph_hazard.capitalize()} {pph_threshold}% PPH vs {outlook_hazard.capitalize()} {outlook_threshold}% Outlook'\n",
    "    ax.set_title(f'{title} ({START_YEAR}-{END_YEAR})', fontsize=16, weight='bold', pad=20)\n",
    "    \n",
    "    # X-axis formatting\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator([1, 7]))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Grid and styling\n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_overlap = np.mean(values)\n",
    "    std_overlap = np.std(values)\n",
    "    max_overlap = np.max(values)\n",
    "    \n",
    "    stats_text = f'Mean: {mean_overlap:.1f}%\\nStd: {std_overlap:.1f}%\\nMax: {max_overlap:.1f}%\\nDays: {len(values):,}'\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "           verticalalignment='top', fontsize=11)\n",
    "    \n",
    "    if len(values) > 30:\n",
    "        ax.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    # Styling\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1.2)\n",
    "    ax.spines['bottom'].set_linewidth(1.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    filename = f\"daily_overlap_{pph_hazard}_{pph_threshold}pct_vs_{outlook_hazard}_{outlook_threshold}pct_{START_YEAR}-{END_YEAR}.png\"\n",
    "    \n",
    "    # Create overlap directory if it doesn't exist\n",
    "    overlap_path = FIGURES_PATH / \"daily_overlap\"\n",
    "    os.makedirs(overlap_path, exist_ok=True)\n",
    "    \n",
    "    save_path = overlap_path / filename\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"💾 Saved overlap plot to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Daily overlap analysis functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 3A: Hail 15% PPH Daily Overlap Analysis\n",
    "print(\"🔄 GENERATING HAIL 15% PPH DAILY OVERLAP PLOTS\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Hail 15% PPH vs different convective outlook thresholds\n",
    "#hail_15_outlook_thresholds = [5, 10, 15, 30, 45, 60]\n",
    "#10% only has 2020 onwards\n",
    "hail_15_outlook_thresholds = [5, 10, 15, 30, 45]\n",
    "\n",
    "for outlook_threshold in hail_15_outlook_thresholds:\n",
    "    print(f\"\\n📊 Processing Hail 15% PPH vs {outlook_threshold}% Outlook...\")\n",
    "    plot_overlap_timeseries('hail', 15, 'hail', outlook_threshold)\n",
    "\n",
    "print(\"\\n✅ Hail 15% PPH overlap plots completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 3B: Hail 30% PPH Daily Overlap Analysis\n",
    "print(\"🔄 GENERATING HAIL 30% PPH DAILY OVERLAP PLOTS\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Hail 30% PPH vs different convective outlook thresholds\n",
    "hail_30_outlook_thresholds = [15, 30]\n",
    "\n",
    "for outlook_threshold in hail_30_outlook_thresholds:\n",
    "    print(f\"\\n📊 Processing Hail 30% PPH vs {outlook_threshold}% Outlook...\")\n",
    "    plot_overlap_timeseries('hail', 30, 'hail', outlook_threshold)\n",
    "\n",
    "print(\"\\n✅ Hail 30% PPH overlap plots completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 3C: SigHail 10% PPH Daily Overlap Analysis\n",
    "print(\"🔄 GENERATING SIGHAIL 10% PPH DAILY OVERLAP PLOTS\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# SigHail 10% PPH vs different convective outlook thresholds\n",
    "sighail_10_outlook_thresholds = [10]\n",
    "\n",
    "for outlook_threshold in sighail_10_outlook_thresholds:\n",
    "    print(f\"\\n📊 Processing SigHail 10% PPH vs {outlook_threshold}% Outlook...\")\n",
    "    plot_overlap_timeseries('sighail', 10, 'sighail', outlook_threshold)\n",
    "\n",
    "print(\"\\n✅ SigHail 10% PPH overlap plots completed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
